{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Date    : Dec-29-21 15:45\n",
    "# @Author  : Kan HUANG (kan.huang@connect.ust.hk)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.linspace(-1.5, 0.3, num=(N * D)).reshape(N, D)\n",
    "captions = (np.arange(N * T) % V).reshape(N, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptioningRNN(nn.Module):\n",
    "    def __init__(self,  word_to_idx, input_dim=512, wordvec_dim=128,\n",
    "                 hidden_dim=128, cell_type='rnn', dtype=torch.float32):\n",
    "        super(CaptioningRNN, self).__init__()\n",
    "        if cell_type not in {'rnn', 'lstm'}:\n",
    "            raise ValueError('Invalid cell_type \"%s\"' % cell_type)\n",
    "\n",
    "        self.cell_type = cell_type\n",
    "        self.dtype = dtype\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "        self.params = {}\n",
    "\n",
    "        vocab_size = len(word_to_idx)\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, wordvec_dim)\n",
    "        self.fc_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        dim_mul = {'lstm': 4, 'rnn': 1}[cell_type]\n",
    "        if cell_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(wordvec_dim, hidden_dim, dim_mul)\n",
    "\n",
    "        self.fc_vocab = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        \"\"\"forward\n",
    "        Inputs:\n",
    "        - features: Input image features, of shape (N, D)\n",
    "        - captions: Ground-truth captions; an integer array of shape (N, T) \n",
    "        \"\"\"\n",
    "        captions_in = captions[:, :-1] # (N, T)\n",
    "        captions_out = captions[:, 1:]\n",
    "\n",
    "        # Initial hidden state\n",
    "        h_prev = self.fc_proj(features) # (N, D) -> (N, H)\n",
    "        h_prev = h_prev.unsqueeze(0) # (N, H) -> (1, N, H)\n",
    "        # print(f\"h_prev.shape: {h_prev.shape}\")\n",
    "\n",
    "        # Use a word embedding layer to transform the words in captions_in from indices to vectors, giving an array of shape (N, T, W).\n",
    "        word_vectors = self.embed(captions_in) # (N, T) -> (N, T, W)\n",
    "\n",
    "        # Must transpose first!\n",
    "        word_vectors = word_vectors.transpose(1, 0) # (N, T, W) -> (T, N, W)\n",
    "        (T, N, W) = word_vectors.shape\n",
    "\n",
    "        # print(f\"word_vectors.shape: {word_vectors.shape}\")\n",
    "        # print(f\"h_prev.shape: {h_prev.shape}\")\n",
    "\n",
    "        # print(f\"word_vectors.shape: {word_vectors.shape}\")\n",
    "        # process the sequence of input word vectors and produce hidden state vectors for all timesteps\n",
    "        for i in range(T):\n",
    "            # step once\n",
    "            output, h_next = self.rnn(word_vectors[i].unsqueeze(0), h_prev)\n",
    "            h_prev = h_next\n",
    "        \n",
    "        loss = None\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_prev.shape: torch.Size([1, 10, 40])\n",
      "word_vectors.shape: torch.Size([12, 10, 30])\n",
      "h_prev.shape: torch.Size([1, 10, 40])\n",
      "word_vectors.shape: torch.Size([12, 10, 30])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-c50cf463750d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "N, D, W, H = 10, 20, 30, 40\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "V = len(word_to_idx)\n",
    "T = 13 # max_length\n",
    "\n",
    "batch_size = N\n",
    "timesteps = T\n",
    "input_dim = D\n",
    "wordvec_dim = W\n",
    "hidden_dim = H\n",
    "\n",
    "model = CaptioningRNN(word_to_idx,\n",
    "          input_dim=input_dim,\n",
    "          wordvec_dim=wordvec_dim,\n",
    "          hidden_dim=hidden_dim,\n",
    "          cell_type='rnn',\n",
    "          dtype=torch.float32)\n",
    "np.random.seed(231)\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "# captions: int\n",
    "captions = torch.randint(vocab_size, size=(batch_size, timesteps))\n",
    "features = torch.randn(batch_size, input_dim)\n",
    "\n",
    "loss = model(features, captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdd02df4a038e808130b65f74f3963603a613d35b6d5a8e2df3811214e297985"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
